<!DOCTYPE HTML>
<html lang="en">
<head>
<meta charset="utf-8">
<title>DISC - Man M. Ho</title>
<link rel="stylesheet" type="text/css" href="css/styles.css">
</head>
<table width="80%" style="margin-left: auto;  margin-right: auto; table-layout:fixed;">
	<tbody>
		<tr>
			<td>
				<h1>DISC: Latent Diffusion Models with Self-Distillation from Separated Conditions for Prostate Cancer Grading</h1>
				<table width="90%" style="margin-left: auto;  margin-right: auto; table-layout:fixed;">
					<tbody>
						<tr>
							<td>
							<span style="font-size: 20px;"><a href="https://minhmanho.github.io/"><b>Man M. Ho<sup>1</sup></b></a></span>
							</td>

							<td>
							<span style="font-size: 20px;"><b>Elham Ghelichkhan<sup>1</sup></b></span>
							</td>

							<td>
							<span style="font-size: 20px;"><b>Yosep Chong<sup>2,4</sup></b></span>
							</td>

							<td>
								<span style="font-size: 20px;"><b>Yufei Zhou<sup>3</sup></b></span>
							</td>

							<td>
							<span style="font-size: 20px;"><b>Beatrice Knudsen<sup>4,5</sup></b></span>
							</td>

							<td>
							<span style="font-size: 20px;"><b>Tolga Tasdizen<sup>1,6</sup></b></span>
							</td>

						</tr>
					</tbody>
				</table>
				<table width="90%" style="margin-left: auto;  margin-right: auto; table-layout:fixed;">
					<tbody>
						<tr>
							<td>
								<br>
								<p>
									<sup>1</sup> Scientific Computing and Imaging Institute, University of Utah, Utah, USA<br>
									<sup>2</sup> The Catholic University of Korea College of Medicine, Seoul, Korea<br>
									<sup>3</sup> Case Western Reserve University, Ohio, USA<br>
									<sup>4</sup> Departmant of Pathology, University of Utah, Utah, USA<br>
									<sup>5</sup> Huntsman Cancer Institute, University of Utah Health, Utah, USA<br>
									<sup>6</sup> Department of Electrical and Computer Engineering, University of Utah, Utah, USA<br>
								</p>
								<br>
							</td>
						</tr>
				</tbody>
				</table>

				<table width="90%" style="margin-left: auto;  margin-right: auto; table-layout:fixed;">
					<tbody>
						<tr>
							<td>
								<a href="https://arxiv.org/abs/2404.13097">[Paper]</a>
							</td>
						</tr>
					</tbody>
				</table>
				<br>
				Abstract accepted for <b>ISBI 2024</b>. <br>
				Extended version to be presented at <b>SynData4CV @ CVPR 2024</b>.
				<br>
				<br>
				<img src="data/application_overview.jpg" width=100%/>
				<br>
				<p style="text-align: justify;">
				</p>
				<hr>
			</td>
		</tr>

		<tr>
			<td style="text-align: justify;">
				<h2>Abstract</h2>
				<br>
				Latent Diffusion Models (LDMs) can generate high-fidelity images from noise, offering a promising approach for augmenting histopathology images for training cancer grading models. While previous works successfully generated high-fidelity histopathology images using LDMs, the generation of image tiles to improve prostate cancer grading has not yet been explored. Additionally, LDMs face challenges in accurately generating admixtures of multiple cancer grades in a tile when conditioned by a tile mask. In this study, we train specific LDMs to generate synthetic tiles that contain multiple Gleason Grades (GGs) by leveraging pixel-wise annotations in input tiles. We introduce a novel framework named Self-Distillation from Separated Conditions (DISC) that generates GG patterns guided by GG masks. Finally, we deploy a training framework for pixel-level and slide-level prostate cancer grading, where synthetic tiles are effectively utilized to improve the cancer grading performance of existing models. As a result, this work surpasses previous works in two domains: (1) our LDMs enhanced with DISC produce more accurate tiles in terms of GG patterns, and (2) our training scheme, incorporating synthetic data, significantly improves the generalization of the baseline model for prostate cancer grading, particularly in challenging cases of rare GG5, demonstrating the potential of generative models to enhance cancer grading when data is limited.
				<hr>
			</td>
		</tr>
		<tr>
			<td style="text-align: justify;">
				<h2>Overview</h2>
				<img src="data/algo_overview.jpg" width=100%/>
				<br>
				Figure: Besides the real patches (top-left) for training pixel-level and slide-level Gleason grading models (right), we introduce Latent Diffusion Models (LDMs) with Self-<b>Di</b>stillation from <b>S</b>eparated <b>C</b>onditions (DISC) to accurately generate admixtures of multiple Gleason Grades in a tile when conditioned by a tile mask (bottom-left).
				<hr>
			</td>
		</tr>

		<tr>
			<td style="text-align: center;">
				<h2>Defining Tile Mask Shapes and Sampling A Bag of Tile Masks</h2>
				<div style="display: flex; justify-content: space-between; align-items: center;">
					<img src="data/define_shapes.jpg" width=45%/>
					<hr style="border: none; border-left: 1px solid black; height: 128px; margin: 0 10px;">
					<img src="data/sampling.jpg" width=45%/>
				</div>
				<br>
				We preprocess human-annotated masks in SICAPv2, converting them to prepared masks with 
				labels mapped to their frequency distribution (semantic information removed). 
				To generate patches from a synthetic WSI indicating a primary GG, we randomly choose a 
				secondary GG and introduce non-overlapped random selection by setting random weights for 
				all labels to control pseudo labels assigned to the patches.
				<hr>
			</td>
		</tr>

		<tr>
			<td style="text-align: center;">
				<h2>Latent Diffusion Models conditioned by Tile Mask</h2>
				<img src="data/sd.jpg" width=60%/>
				<br>
				Latent Diffusion Models (Stable Diffusion) conditioned by guided masks with multiple Gleason Grades (GGs)
				<hr>
			</td>
		</tr>

		<tr>
			<td style="text-align: center;">
				<h2>Denoising with Self-Distillation from Separated Conditions (DISC)</h2>
				<img src="data/disc_disc.jpg" width=60%/>
				<br>
				We introduce Self-Distillation from Separated Conditions (DISC) to improve image synthesis accuracy. 
				Instead of using the initial complex guided mask with multiple Gleason Grades (GGs) (<b>top</b>), we generate 
				separate latent features with distinct labels, which are fused with the mask in the final step for robust 
				patterns. However, this approach incurs a computational cost of K times, the number of labels. To address 
				this, we train the main process to distill information from fused latent features obtained from the 
				Condition-Separated Denoising Process (<b>bottom</b>).
				<hr>
			</td>
		</tr>

		<tr>
			<td>
				<h2>Improving Stable Diffusion (SD)</h2>
				<br>
				<img src="data/comparison_synthetic_tiles.jpg" width=100%/>
				<!-- A qualitative comparison between LayoutDiffusion (LD), Stable Diffusion (SD), and our proposed technique, SD with Self-Distillation from Separated Conditions (DISC) for histopathology image synthesis. This work yields higher-confidence label patterns compared to LayoutDiffusion and SD. Notably, 
				LD tends to ignore small bounding boxes to generate patterns for larger bounding boxes (rows 4 and 5),
				while SD tends to generate fused glands representing GG4 for Non-Cancer regions (highlighted rectangles) and sheets of cells representing GG5 for GG3-indicated regions(indicated by yellow arrows).
				Labels (also applied for layouts in column 2): Non-Cancer(green), GG3(blue), GG4(yellow), GG5(red). -->
				<p>
					Figure: A qualitative comparison between Stable Diffusion (SD) and our proposed technique, SD with Self-Distillation from Separated Conditions (DISC), for histopathology image synthesis. This work yields higher-confidence label patterns compared to SD. Notably, SD tends to generate fused glands representing GG4 for Non-Cancer regions (highlighted rectangles) and sheets of cells representing GG5 for GG3-indicated regions<span style="color: rgb(190, 190, 0);"> (indicated by yellow arrows)</span>.
				<em>Labels</em>: <span style="color: green;">Non-Cancer</span>, <span style="color: blue;">GG3</span>, <span style="color: rgb(190, 190, 0);">GG4</span>, <span style="color: red;">GG5</span>.
				</p>	
				<hr>
			</td>
		</tr>
		<tr>
			<td>
				<h2>Improving Pixel-Level Cancer Grading Models (CarcinoNet)</h2>
				<br>
				<img src="data/comparison_segmentation.jpg" width=100%/>
				<p>
					Figure: Qualitative comparison between Carcino-Net and itself trained with our techniques.
				</p>
				<hr>
			</td>
		</tr>
		<tr>
			<td>
				<h2>Improving MIL-based Cancer Grading Models (TransMIL)</h2>
				<br>
				<img src="data/charts.png" width=100%/>
				<p>
					Charts: A quantitative comparison among TransMIL, Mixed Supervision, and TransMIL jointly trained with tiles generated by our models with a balance weight λ ∈ [0.0, 0.9] in AUCROC. The feature representation extractor used is ViT-small (patch of 16) pre-trained on histopathology images with DINO. All models are trained on the SICAPv2 and evaluated on both in-distribution SICAPv2 and Out-Of-Distribution (OOD) PANDA. Our generated data consistently improves cancer grading performance with higher AUCROC. Please check our Supplemental Document for more results including the feature representation extractors ResNet50 pre-trained on ImageNet and histopathology images with MoCov2.
				</p>				
				<hr>
			</td>
		</tr>
		<tr>
			<td style="font-size: 14px; text-align: left;">
				<h2>If you find our work useful, please consider citing</h2>
				<br>
				<code>
					@misc{ho2024disc, <br>
						&nbsp;&nbsp;&nbsp;title={DISC: Latent Diffusion Models with Self-Distillation from Separated Conditions for Prostate Cancer Grading}, <br>
						&nbsp;&nbsp;&nbsp;author={Man M. Ho and Elham Ghelichkhan and Yosep Chong and Yufei Zhou and Beatrice Knudsen and Tolga Tasdizen}, <br>
						&nbsp;&nbsp;&nbsp;year={2024}, <br>
						&nbsp;&nbsp;&nbsp;eprint={2404.13097}, <br>
						&nbsp;&nbsp;&nbsp;archivePrefix={arXiv}, <br>
						&nbsp;&nbsp;&nbsp;primaryClass={eess.IV} <br>
				  }
				</code>
				<hr>
			</td>
		</tr>
		<tr>
			<td>
				<h2>License</h2>
				<br>
				This work, including the trained models, code, and dataset, is for non-commercial uses and research purposes only.
				<hr>
			</td>
		</tr>
		<tr>
			<td style="text-align: left;">
				<h2>References</h2>
				<br>
				<b>[Stable Diffusion]</b>: Rombach, Robin, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. "High-resolution image synthesis with latent diffusion models." In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 10684-10695. 2022. <br>
				<b>[CarcinoNet]</b>: Lokhande, Avinash, Saikiran Bonthu, and Nitin Singhal. "Carcino-Net: A deep learning framework for automated Gleason grading of prostate biopsies." In 2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), pp. 1380-1383. IEEE, 2020. <br>
				<b>[TransMIL]</b>: Shao, Zhuchen, Hao Bian, Yang Chen, Yifeng Wang, Jian Zhang, and Xiangyang Ji. "Transmil: Transformer based correlated multiple instance learning for whole slide image classification." Advances in neural information processing systems 34 (2021): 2136-2147. <br>
				<b>[Mixed Supervision]</b>: Bian, Hao, Zhuchen Shao, Yang Chen, Yifeng Wang, Haoqian Wang, Jian Zhang, and Yongbing Zhang. "Multiple instance learning with mixed supervision in gleason grading." In International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 204-213. Cham: Springer Nature Switzerland, 2022.
				<hr>
			</td>
		</tr>
		<tr>
			<td>
				<h2>Acknowledgements</h2>
				<br>
				We acknowledge the generous support from the Department of Defense Prostate Cancer Program Population Science Award (grant number W81XWH-21-0725); and also, the VA Merit Award (grant number 1 I01 CX002622-01). We also thank Dr. Akadiusz Gertych for the dataset from Cedars-Sinai Hospital in Los Angeles.
				<hr>
			</td>
		</tr>
</tbody>
</table>
<br>

</html>
